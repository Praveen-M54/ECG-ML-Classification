{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "This notebook downloads the entire MIT-BIH Arrhythmia Database, which is publicly available here: https://physionet.org/physiobank/database/mitdb/\n",
    "\n",
    "It then converts all the WFDB files into CSV files with the same name (example the files 100.dat, 100.hea, 100.atr into 100.csv).\n",
    "\n",
    "Each row in the CSV file corresponds to a single heartbeat and is generated as follows:\n",
    "* Split MIT-BIH record at the R-peaks into individual heartbeat records.\n",
    "* Each heartbeat record is appended with the first 40 readings of the next heartbeat record so that we include a full QRS Complex.\n",
    "* Resample each heartbeat record from 360Hz to 125Hz.\n",
    "* Normalize the mV readings to a 0-1 range.\n",
    "* Heartbeat records longer than 187 values are discarded.\n",
    "* Heartbeat records are padded with zeroes at the end until they contain exactly 187 values.\n",
    "* Heartbeat classifications from the annotations is reduced to just Normal and Abnormal and appended to the end of each heartbeat record (0 is normal, 1 is abnormal). Each row then contains exactly 188 values.\n",
    "* Heartbeat records without classifications are discarded.\n",
    "\n",
    "The purpose of these CSV files is so that they can be used in training the ECG model for classifying heartbeats as either Normal or Abnormal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize\n",
    "Import dependencies.\n",
    "\n",
    "Note that you will need to download and install the [mitdb](https://github.com/Nospoko/qrs-tutorial) library. The project contains convenience functions that make it easier to download and read [WFDB](https://physionet.org/physiotools/wfdb.shtml) compatible files. In addition, you will also need to install the [BioSPPy](https://github.com/PIA-Group/BioSPPy) library, which we use to find the R-peaks in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tqdm\n",
    "%pip install wfdb\n",
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "!pip install biosppy\n",
    "from biosppy.signals import ecg\n",
    "!pip install wfdb\n",
    "import wfdb as wf\n",
    "wf.dl_database('mitdb', './mitdb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Conversion\n",
    "Read the WFDB files and convert to CSV files. Data will be split into individual heartbeats, each row consisting of exactly 187 normalized and resampled values, plus the last value with be an integer representing the classification; 0 = Normal, 1 = Abnormal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating record list for: 100\n",
      "Generating record list for: 101\n",
      "Generating record list for: 102\n",
      "Generating record list for: 103\n",
      "Generating record list for: 104\n",
      "Generating record list for: 105\n",
      "Generating record list for: 106\n",
      "Generating record list for: 107\n",
      "Generating record list for: 108\n",
      "Generating record list for: 109\n",
      "Generating record list for: 111\n",
      "Generating record list for: 112\n",
      "Generating record list for: 113\n",
      "Generating record list for: 114\n",
      "Generating record list for: 115\n",
      "Generating record list for: 116\n",
      "Generating record list for: 117\n",
      "Generating record list for: 118\n",
      "Generating record list for: 119\n",
      "Generating record list for: 121\n",
      "Generating record list for: 122\n",
      "Generating record list for: 123\n",
      "Generating record list for: 124\n",
      "Generating record list for: 200\n",
      "Generating record list for: 201\n",
      "Generating record list for: 202\n",
      "Generating record list for: 203\n",
      "Generating record list for: 205\n",
      "Generating record list for: 207\n",
      "Generating record list for: 208\n",
      "Generating record list for: 209\n",
      "Generating record list for: 210\n",
      "Generating record list for: 212\n",
      "Generating record list for: 213\n",
      "Generating record list for: 214\n",
      "Generating record list for: 215\n",
      "Generating record list for: 217\n",
      "Generating record list for: 219\n",
      "Generating record list for: 220\n",
      "Generating record list for: 221\n",
      "Generating record list for: 222\n",
      "Generating record list for: 223\n",
      "Generating record list for: 228\n",
      "Generating record list for: 230\n",
      "Generating record list for: 231\n",
      "Generating record list for: 232\n",
      "Generating record list for: 233\n",
      "Generating record list for: 234\n",
      "Generating list of all files for: 100\n",
      "Generating list of all files for: 101\n",
      "Generating list of all files for: 102\n",
      "Generating list of all files for: 103\n",
      "Generating list of all files for: 104\n",
      "Generating list of all files for: 105\n",
      "Generating list of all files for: 106\n",
      "Generating list of all files for: 107\n",
      "Generating list of all files for: 108\n",
      "Generating list of all files for: 109\n",
      "Generating list of all files for: 111\n",
      "Generating list of all files for: 112\n",
      "Generating list of all files for: 113\n",
      "Generating list of all files for: 114\n",
      "Generating list of all files for: 115\n",
      "Generating list of all files for: 116\n",
      "Generating list of all files for: 117\n",
      "Generating list of all files for: 118\n",
      "Generating list of all files for: 119\n",
      "Generating list of all files for: 121\n",
      "Generating list of all files for: 122\n",
      "Generating list of all files for: 123\n",
      "Generating list of all files for: 124\n",
      "Generating list of all files for: 200\n",
      "Generating list of all files for: 201\n",
      "Generating list of all files for: 202\n",
      "Generating list of all files for: 203\n",
      "Generating list of all files for: 205\n",
      "Generating list of all files for: 207\n",
      "Generating list of all files for: 208\n",
      "Generating list of all files for: 209\n",
      "Generating list of all files for: 210\n",
      "Generating list of all files for: 212\n",
      "Generating list of all files for: 213\n",
      "Generating list of all files for: 214\n",
      "Generating list of all files for: 215\n",
      "Generating list of all files for: 217\n",
      "Generating list of all files for: 219\n",
      "Generating list of all files for: 220\n",
      "Generating list of all files for: 221\n",
      "Generating list of all files for: 222\n",
      "Generating list of all files for: 223\n",
      "Generating list of all files for: 228\n",
      "Generating list of all files for: 230\n",
      "Generating list of all files for: 231\n",
      "Generating list of all files for: 232\n",
      "Generating list of all files for: 233\n",
      "Generating list of all files for: 234\n",
      "Downloading files...\n",
      "Finished downloading files\n",
      "Total files: 48\n",
      "Processing record: 100\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\100_MLII.csv\n",
      "  Processing channel: V5\n",
      "  Saving to: ./data_ecg\\100_V5.csv\n",
      "Processing record: 101\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\101_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\101_V1.csv\n",
      "Processing record: 102\n",
      "  Processing channel: V5\n",
      "  Saving to: ./data_ecg\\102_V5.csv\n",
      "  Processing channel: V2\n",
      "  Saving to: ./data_ecg\\102_V2.csv\n",
      "Processing record: 103\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\103_MLII.csv\n",
      "  Processing channel: V2\n",
      "  Saving to: ./data_ecg\\103_V2.csv\n",
      "Processing record: 104\n",
      "  Processing channel: V5\n",
      "  Saving to: ./data_ecg\\104_V5.csv\n",
      "  Processing channel: V2\n",
      "  Saving to: ./data_ecg\\104_V2.csv\n",
      "Processing record: 105\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\105_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\105_V1.csv\n",
      "Processing record: 106\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\106_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\106_V1.csv\n",
      "Processing record: 107\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\107_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\107_V1.csv\n",
      "Processing record: 108\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\108_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\108_V1.csv\n",
      "Processing record: 109\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\109_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\109_V1.csv\n",
      "Processing record: 111\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\111_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\111_V1.csv\n",
      "Processing record: 112\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\112_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\112_V1.csv\n",
      "Processing record: 113\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\113_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\113_V1.csv\n",
      "Processing record: 114\n",
      "  Processing channel: V5\n",
      "  Saving to: ./data_ecg\\114_V5.csv\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\114_MLII.csv\n",
      "Processing record: 115\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\115_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\115_V1.csv\n",
      "Processing record: 116\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\116_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\116_V1.csv\n",
      "Processing record: 117\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\117_MLII.csv\n",
      "  Processing channel: V2\n",
      "  Saving to: ./data_ecg\\117_V2.csv\n",
      "Processing record: 118\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\118_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\118_V1.csv\n",
      "Processing record: 119\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\119_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\119_V1.csv\n",
      "Processing record: 121\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\121_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\121_V1.csv\n",
      "Processing record: 122\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\122_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\122_V1.csv\n",
      "Processing record: 123\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\123_MLII.csv\n",
      "  Processing channel: V5\n",
      "  Saving to: ./data_ecg\\123_V5.csv\n",
      "Processing record: 124\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\124_MLII.csv\n",
      "  Processing channel: V4\n",
      "  Saving to: ./data_ecg\\124_V4.csv\n",
      "Processing record: 200\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\200_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\200_V1.csv\n",
      "Processing record: 201\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\201_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\201_V1.csv\n",
      "Processing record: 202\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\202_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\202_V1.csv\n",
      "Processing record: 203\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\203_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\203_V1.csv\n",
      "Processing record: 205\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\205_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\205_V1.csv\n",
      "Processing record: 207\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\207_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\207_V1.csv\n",
      "Processing record: 208\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\208_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\208_V1.csv\n",
      "Processing record: 209\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\209_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\209_V1.csv\n",
      "Processing record: 210\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\210_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\210_V1.csv\n",
      "Processing record: 212\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\212_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\212_V1.csv\n",
      "Processing record: 213\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\213_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\213_V1.csv\n",
      "Processing record: 214\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\214_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\214_V1.csv\n",
      "Processing record: 215\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\215_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\215_V1.csv\n",
      "Processing record: 217\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\217_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\217_V1.csv\n",
      "Processing record: 219\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\219_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\219_V1.csv\n",
      "Processing record: 220\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\220_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\220_V1.csv\n",
      "Processing record: 221\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\221_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\221_V1.csv\n",
      "Processing record: 222\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\222_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\222_V1.csv\n",
      "Processing record: 223\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\223_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\223_V1.csv\n",
      "Processing record: 228\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\228_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\228_V1.csv\n",
      "Processing record: 230\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\230_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\230_V1.csv\n",
      "Processing record: 231\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\231_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\231_V1.csv\n",
      "Processing record: 232\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\232_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\232_V1.csv\n",
      "Processing record: 233\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\233_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\233_V1.csv\n",
      "Processing record: 234\n",
      "  Processing channel: MLII\n",
      "  Saving to: ./data_ecg\\234_MLII.csv\n",
      "  Processing channel: V1\n",
      "  Saving to: ./data_ecg\\234_V1.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from biosppy.signals import ecg\n",
    "import wfdb as wf\n",
    "\n",
    "# Download the MIT-BIH dataset\n",
    "wf.dl_database('mitdb', './mitdb')\n",
    "\n",
    "# Create output directory for CSV files\n",
    "output_dir = './data_ecg'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define real beat classifications\n",
    "realbeats = ['N', 'L', 'R', 'B', 'A', 'a', 'J', 'S', 'V', 'r', \n",
    "             'F', 'e', 'j', 'n', 'E', '/', 'f', 'Q', '?']\n",
    "\n",
    "# List available records\n",
    "records = wf.get_record_list('mitdb')\n",
    "print(f'Total files: {len(records)}')\n",
    "\n",
    "# Iterate through each record\n",
    "for record_name in records:\n",
    "    print(f'Processing record: {record_name}')\n",
    "    record_path = f'./mitdb/{record_name}'\n",
    "\n",
    "    # Load record and annotations\n",
    "    record = wf.rdsamp(record_path)\n",
    "    annotation = wf.rdann(record_path, 'atr')\n",
    "\n",
    "    # Sampling frequency\n",
    "    fs = record[1]['fs']\n",
    "\n",
    "    # ECG data and annotations\n",
    "    data = record[0].T\n",
    "    annotations = annotation.sample\n",
    "    symbols = annotation.symbol\n",
    "\n",
    "    # Initialize classifications for beats\n",
    "    classifications = np.zeros(len(annotations), dtype=float)\n",
    "    for i, sym in enumerate(symbols):\n",
    "        if sym == 'N':\n",
    "            classifications[i] = 0  # Normal\n",
    "        elif sym in realbeats:\n",
    "            classifications[i] = 1  # Abnormal\n",
    "\n",
    "    # Process each channel in the record\n",
    "    for channel_index, channel_data in enumerate(data):\n",
    "        channel_name = record[1]['sig_name'][channel_index]\n",
    "        print(f'  Processing channel: {channel_name}')\n",
    "\n",
    "        # Detect R-peaks using biosppy\n",
    "        ecg_output = ecg.ecg(signal=channel_data, sampling_rate=fs, show=False)\n",
    "        rpeaks = ecg_output['rpeaks']\n",
    "\n",
    "        # Prepare to store processed beats\n",
    "        all_beats = []\n",
    "\n",
    "        # Split and process individual heartbeats\n",
    "        for i in range(1, len(rpeaks) - 1):  # Skip first and last R-peak\n",
    "            start = rpeaks[i - 1]\n",
    "            end = rpeaks[i + 1]\n",
    "\n",
    "            # Boundary checks\n",
    "            if start < 0 or end > len(channel_data):\n",
    "                continue\n",
    "\n",
    "            beat = channel_data[start:end]\n",
    "            if len(beat) == 0:  # Skip empty beats\n",
    "                continue\n",
    "\n",
    "            # Normalize the beat\n",
    "            beat = (beat - beat.min()) / (beat.max() - beat.min() + 1e-8)\n",
    "            resampled_beat = signal.resample(beat, 187)\n",
    "\n",
    "            # Get the classification for the beat\n",
    "            classification = classifications[i] if i < len(classifications) else 0\n",
    "            labeled_beat = np.append(resampled_beat, classification)\n",
    "            all_beats.append(labeled_beat)\n",
    "\n",
    "        # Save processed beats to a CSV file\n",
    "        if len(all_beats) > 0:  # Ensure there are beats to save\n",
    "            all_beats = np.array(all_beats, dtype=np.float32)\n",
    "            output_file = os.path.join(output_dir, f'{record_name}_{channel_name}.csv')\n",
    "            print(f'  Saving to: {output_file}')\n",
    "            np.savetxt(output_file, all_beats, delimiter=',', fmt='%f')\n",
    "        else:\n",
    "            print(f'  No valid beats found for {record_name}_{channel_name}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
